{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1rakIM6O4JnAPO_M21NGpzN_9NyPkqXXK","authorship_tag":"ABX9TyN4YuvHEZ3aCIn+Dnck5Qqb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vHcke57bKWY2"},"outputs":[],"source":["# IndustryMapper â€“ Desktop app (Streamlit) packaged as .exe\n","# Upload Beauhurst CSV â†’ get mapped dataset + unmatched report\n","# Supports:\n","#   - Single \"Industries\" column (comma/semicolon separated)\n","#   - Multiple \"Industries - X\" boolean columns\n","# Uses mapping_default.csv by default; users can upload a different mapping if desired.\n","\n","import streamlit as st\n","import pandas as pd\n","import numpy as np\n","import re, os, sys\n","from io import BytesIO\n","from difflib import get_close_matches\n","\n","st.set_page_config(page_title=\"Industry â†’ Category Mapper\", page_icon=\"ğŸ§­\", layout=\"centered\")\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# Helpers\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","def resource_path(relative_path: str) -> str:\n","    \"\"\"\n","    Resolve path for bundled resources whether running as script or PyInstaller exe.\n","    \"\"\"\n","    if hasattr(sys, \"_MEIPASS\"):\n","        base = sys._MEIPASS  # PyInstaller temp dir\n","    else:\n","        base = os.path.abspath(\".\")\n","    return os.path.join(base, relative_path)\n","\n","def clean_text(s: str) -> str:\n","    if s is None or (isinstance(s, float) and pd.isna(s)):\n","        return \"\"\n","    s = str(s)\n","    s = re.sub(r'[\\u2013\\u2014]', '-', s)  # en/em dash â†’ hyphen\n","    s = re.sub(r'&', 'AND', s)\n","    s = re.sub(r'/', ' / ', s)\n","    s = re.sub(r'\\s+', ' ', s).strip()\n","    return s.upper()\n","\n","def split_industries(cell: str):\n","    if cell is None or str(cell).strip() == \"\":\n","        return []\n","    parts = re.split(r'[;,]', str(cell))\n","    cleaned = [clean_text(p) for p in parts if str(p).strip() != \"\"]\n","    return [p for p in cleaned if p]\n","\n","def normalize_bool_series(s: pd.Series) -> pd.Series:\n","    return (s.astype(str).str.strip().str.upper()\n","            .map({'TRUE': True, 'FALSE': False, 'YES': True, 'NO': False, '1': True, '0': False})\n","            .fillna(False))\n","\n","def detect_company_col(df: pd.DataFrame) -> str:\n","    candidates = [c for c in df.columns if c.lower().strip() in {\n","        'companyname','company name','company','name','company_name'\n","    }]\n","    return candidates[0] if candidates else df.columns[0]\n","\n","def infer_category_columns(mapping_df: pd.DataFrame) -> list:\n","    cats = [c for c in mapping_df.columns if c.lower().strip() != 'industry']\n","    keep = []\n","    for c in cats:\n","        col = normalize_bool_series(mapping_df[c])\n","        if col.any():  # at least one True\n","            keep.append(c)\n","    return keep\n","\n","def melt_mapping(mapping_df: pd.DataFrame, category_columns: list) -> pd.DataFrame:\n","    m = mapping_df.copy()\n","    if 'Industry' not in m.columns:\n","        raise KeyError(\"Mapping must contain an 'Industry' column.\")\n","    m['Industry_Clean'] = m['Industry'].apply(clean_text)\n","    for cat in category_columns:\n","        if cat not in m.columns:\n","            m[cat] = False\n","        m[cat] = normalize_bool_series(m[cat])\n","    cat_long = (\n","        m.melt(id_vars=['Industry_Clean'], value_vars=category_columns,\n","               var_name='Category', value_name='Flag')\n","         .query('Flag == True')\n","         .drop(columns='Flag')\n","         .drop_duplicates()\n","    )\n","    return cat_long\n","\n","def detect_input_format(df: pd.DataFrame):\n","    cols_lower = [c.lower() for c in df.columns]\n","    if 'industries' in cols_lower:\n","        return 'single'\n","    wide = [c for c in df.columns if c.lower().startswith('industries - ')]\n","    return 'wide' if wide else None\n","\n","def bytes_from_df(df: pd.DataFrame) -> BytesIO:\n","    buf = BytesIO()\n","    df.to_csv(buf, index=False)\n","    buf.seek(0)\n","    return buf\n","\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","# UI\n","# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n","\n","st.title(\"ğŸ§­ Industry â†’ Category Mapper\")\n","st.caption(\"Drop a Beauhurst CSV in. Get a clean mapped CSV out. No code. No excuses.\")\n","\n","with st.expander(\"How it works\", expanded=False):\n","    st.markdown(\n","        \"- Supports a single **Industries** text column or multiple **Industries - X** boolean columns.\\n\"\n","        \"- Uses the **company default mapping** bundled with the app, or you can upload a new mapping CSV.\\n\"\n","        \"- Outputs: mapped dataset + unmatched industries report with fuzzy suggestions.\"\n","    )\n","\n","# Mapping source controls\n","use_default_mapping = st.checkbox(\"Use company default mapping (mapping_default.csv)\", value=True)\n","uploaded_mapping = None\n","if not use_default_mapping:\n","    uploaded_mapping = st.file_uploader(\"Or upload a mapping CSV (must include 'Industry' + category columns)\", type=['csv'])\n","\n","# Data file\n","data_file = st.file_uploader(\"Upload Beauhurst dataset (CSV)\", type=['csv'])\n","\n","# Fuzzy cutoff slider\n","fuzzy_cutoff = st.slider(\"Fuzzy suggestion cutoff (higher = stricter)\", 0.50, 0.95, 0.80, 0.01)\n","\n","if data_file:\n","    # Load dataset\n","    try:\n","        df = pd.read_csv(data_file, dtype=str, keep_default_na=False, na_values=['', 'NA', 'NaN'])\n","    except Exception as e:\n","        st.error(f\"Could not read dataset CSV: {e}\")\n","        st.stop()\n","\n","    # Load mapping\n","    try:\n","        if uploaded_mapping is not None:\n","            mapping = pd.read_csv(uploaded_mapping, dtype=str)\n","        else:\n","            default_path = resource_path('mapping_default.csv')\n","            mapping = pd.read_csv(default_path, dtype=str)\n","    except Exception as e:\n","        st.error(f\"Could not read mapping CSV: {e}\")\n","        st.stop()\n","\n","    # Determine categories from mapping\n","    try:\n","        category_columns = infer_category_columns(mapping)\n","    except KeyError as ke:\n","        st.error(str(ke))\n","        st.stop()\n","\n","    if not category_columns:\n","        st.error(\"No valid category columns detected in mapping CSV (columns other than 'Industry' should contain True values).\")\n","        st.stop()\n","\n","    with st.expander(\"Detected category columns\", expanded=False):\n","        st.write(category_columns)\n","\n","    # Detect format + company column\n","    fmt = detect_input_format(df)\n","    if fmt is None:\n","        st.error(\"Could not detect dataset format. Expect either a single 'Industries' column, or multiple 'Industries - X' columns.\")\n","        st.stop()\n","    st.info(f\"Detected dataset format: **{fmt}**\")\n","\n","    company_col = detect_company_col(df)\n","    company_col = st.selectbox(\"Company name column\", options=list(df.columns),\n","                               index=list(df.columns).index(company_col))\n","\n","    # Build mapping\n","    cat_long = melt_mapping(mapping, category_columns)\n","    mapped_tokens = set(cat_long['Industry_Clean'].unique())\n","\n","    # Compute row-id\n","    df['_ROW_ID'] = np.arange(len(df))\n","\n","    # Prepare tokens\n","    if fmt == 'single':\n","        tmp = df[['_ROW_ID', company_col, 'Industries']].copy()\n","        tmp['Industry_Clean'] = tmp['Industries'].apply(split_industries)\n","        tmp = tmp.explode('Industry_Clean', ignore_index=False)\n","        tmp = tmp[tmp['Industry_Clean'].notna() & (tmp['Industry_Clean'] != '')]\n","    else:\n","        industry_cols = [c for c in df.columns if c.lower().startswith('industries - ')]\n","        wide = df[['_ROW_ID', company_col] + industry_cols].copy()\n","        for c in industry_cols:\n","            wide[c] = normalize_bool_series(wide[c])\n","        melted = wide.melt(id_vars=['_ROW_ID', company_col], var_name='col', value_name='Flag')\n","        melted = melted[melted['Flag'] == True].copy()\n","        melted['Industry_Clean'] = melted['col'].str.replace(r'(?i)^industries\\s*-\\s*', '', regex=True).map(clean_text)\n","        tmp = melted[['_ROW_ID', company_col, 'Industry_Clean']].copy()\n","\n","    # Join to mapping, pivot to booleans per category\n","    joined = tmp.merge(cat_long, on='Industry_Clean', how='left')\n","    has_cat = (\n","        joined.dropna(subset=['Category'])\n","              .assign(val=True)\n","              .pivot_table(index='_ROW_ID', columns='Category', values='val',\n","                           aggfunc='any', fill_value=False)\n","              .reindex(columns=category_columns, fill_value=False)\n","    )\n","\n","    out_df = df.copy()\n","    for cat in category_columns:\n","        if cat not in out_df.columns:\n","            out_df[cat] = False\n","    for cat in category_columns:\n","        if cat in has_cat.columns:\n","            out_df.loc[has_cat.index, cat] = has_cat[cat].astype(bool)\n","\n","    # Unmatched\n","    all_tokens = set(tmp['Industry_Clean'].dropna().unique())\n","    unmatched_tokens = sorted(all_tokens - mapped_tokens)\n","\n","    unmatched_df = pd.DataFrame(columns=['Industry_Clean', 'count', 'sample_company', 'suggested_mapping'])\n","    if unmatched_tokens:\n","        freq = (\n","            tmp[tmp['Industry_Clean'].isin(unmatched_tokens)]\n","              .groupby('Industry_Clean', as_index=False)\n","              .agg(count=('Industry_Clean', 'size'),\n","                   sample_company=(company_col, 'first'))\n","              .sort_values('count', ascending=False)\n","        )\n","        vocab = list(mapped_tokens)\n","        def suggest(x):\n","            m = get_close_matches(x, vocab, n=1, cutoff=fuzzy_cutoff)\n","            return m[0] if m else ''\n","        freq['suggested_mapping'] = freq['Industry_Clean'].apply(suggest)\n","        unmatched_df = freq\n","\n","    # Stats\n","    st.subheader(\"Category coverage (unique companies)\")\n","    stats = []\n","    for cat in category_columns:\n","        stats.append({'Category': cat,\n","                      'Companies': out_df.loc[out_df[cat] == True, company_col].nunique()})\n","    st.dataframe(pd.DataFrame(stats).sort_values('Companies', ascending=False), use_container_width=True)\n","\n","    # Preview\n","    st.subheader(\"Preview\")\n","    preview_cols = [company_col]\n","    if 'Industries' in out_df.columns: preview_cols.append('Industries')\n","    preview_cols += category_columns\n","    st.dataframe(out_df[preview_cols].head(20), use_container_width=True)\n","\n","    # Downloads\n","    st.subheader(\"Download\")\n","    st.download_button(\n","        \"â¬‡ï¸ Mapped dataset (CSV)\",\n","        data=bytes_from_df(out_df.drop(columns=['_ROW_ID'], errors='ignore')),\n","        file_name=\"mapped_dataset.csv\",\n","        mime=\"text/csv\"\n","    )\n","    st.download_button(\n","        \"â¬‡ï¸ Unmatched industries report (CSV)\",\n","        data=bytes_from_df(unmatched_df),\n","        file_name=\"unmatched_industries_report.csv\",\n","        mime=\"text/csv\",\n","        disabled=unmatched_df.empty\n","    )\n","\n","else:\n","    st.info(\"Upload a Beauhurst CSV to begin. The default mapping will be used unless you upload another.\")\n","\n","with st.expander(\"Tips\", expanded=False):\n","    st.markdown(\n","        \"- If you see many unmatched labels, check for missing commas or odd spellings in the source.\\n\"\n","        \"- To update the default mapping for everyone, replace **mapping_default.csv** in the app folder (no rebuild needed).\\n\"\n","        \"- Running from a network share can be slower; copying the EXE locally is faster.\"\n","    )"]}]}